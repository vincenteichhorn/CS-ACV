{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da4cad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pil torch torchvision pandas numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "caa7c4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da62de15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['azimuth.npy', 'positions.csv', 'lidar', 'colors.csv', 'rgb', 'pointcloud', 'distance', 'zenith.npy']\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 32\n",
    "VALID_BATCHES = 10\n",
    "N = 9999   \n",
    "NUM_POSITIONS = 9\n",
    "\n",
    "DATA_DIR = \"../../../NVIDIA Multimodal Models/code/data/replicator_data_cubes/\"\n",
    "# drive.mount('/content/drive')\n",
    "# DATA_DIR = \"/content/drive/MyDrive/data/replicator_data_cubes/\"\n",
    "\n",
    "print(list(os.listdir(DATA_DIR)))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7f5c3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),  # Scales data into [0,1]\n",
    "])\n",
    "\n",
    "def get_torch_xyza(lidar_depth, azimuth, zenith):\n",
    "    x = lidar_depth * torch.sin(-azimuth[:, None]) * torch.cos(-zenith[None, :])\n",
    "    y = lidar_depth * torch.cos(-azimuth[:, None]) * torch.cos(-zenith[None, :])\n",
    "    z = lidar_depth * torch.sin(-zenith[None, :])\n",
    "    a = torch.where(lidar_depth < 50.0, torch.ones_like(lidar_depth), torch.zeros_like(lidar_depth))\n",
    "    xyza = torch.stack((x, y, z, a))\n",
    "    return xyza\n",
    "\n",
    "class ReplicatorDataset(Dataset):\n",
    "    def __init__(self, root_dir, start_idx, stop_idx):\n",
    "        self.root_dir = root_dir\n",
    "        self.rgb_imgs = []\n",
    "        self.lidar_depths = []\n",
    "        self.positions = np.genfromtxt(\n",
    "            root_dir + \"positions.csv\", delimiter=\",\", skip_header=1\n",
    "        )[start_idx:stop_idx]\n",
    "        \n",
    "\n",
    "        azimuth = np.load(self.root_dir + \"azimuth.npy\")\n",
    "        zenith = np.load(self.root_dir + \"zenith.npy\")\n",
    "        self.azimuth = torch.from_numpy(azimuth).to(device)\n",
    "        self.zenith = torch.from_numpy(zenith).to(device)\n",
    "\n",
    "        for idx in range(start_idx, stop_idx):\n",
    "            file_number = \"{:04d}\".format(idx)\n",
    "            rbg_img = Image.open(self.root_dir + \"rgb/\" + file_number + \".png\")\n",
    "            rbg_img = img_transforms(rbg_img).to(device)\n",
    "            self.rgb_imgs.append(rbg_img)\n",
    "\n",
    "            lidar_depth = np.load(self.root_dir + \"lidar/\" + file_number + \".npy\")\n",
    "            lidar_depth = torch.from_numpy(lidar_depth).to(torch.float32).to(device)\n",
    "            self.lidar_depths.append(lidar_depth)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.positions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rbg_img = self.rgb_imgs[idx]\n",
    "        lidar_depth = self.lidar_depths[idx]\n",
    "        lidar_xyza = get_torch_xyza(lidar_depth, self.azimuth, self.zenith)\n",
    "\n",
    "        position = self.positions[idx]\n",
    "        position = torch.from_numpy(position).to(torch.float32).to(device)\n",
    "\n",
    "        return rbg_img, lidar_xyza, position\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "799a1ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ReplicatorDataset(DATA_DIR, 0, N-VALID_BATCHES*BATCH_SIZE)\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "valid_data = ReplicatorDataset(DATA_DIR, N-VALID_BATCHES*BATCH_SIZE, N)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e5fdc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNet(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size=3):\n",
    "        super().__init__()\n",
    "        flattened_size = 200 * 8 * 8\n",
    "        self.conv1 = nn.Conv2d(in_ch, 50, kernel_size, padding=1)\n",
    "        self.conv2 = nn.Conv2d(50, 100, kernel_size, padding=1)\n",
    "        self.conv3 = nn.Conv2d(100, 200, kernel_size, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(flattened_size, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 100)\n",
    "        self.fc3 = nn.Linear(100, out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class EarlyNet(nn.Module):\n",
    "    def __init__(self, in_chs, out_ch):\n",
    "        super().__init__()\n",
    "        self.base_net = BaseNet(sum(in_chs), out_ch)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = torch.cat(inputs, 1)\n",
    "        x = self.base_net(x)\n",
    "        return x\n",
    "    \n",
    "class LateNet(nn.Module):\n",
    "    def __init__(self, networks, out_chs):\n",
    "        super().__init__()\n",
    "        self.networks = networks\n",
    "        sum_out_chs = sum(out_chs)\n",
    "        self.fc1 = nn.Linear(sum_out_chs, sum_out_chs * 10)\n",
    "        self.fc2 = nn.Linear(sum_out_chs * 10, sum_out_chs)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        network_inputs = [net(inp) for net, inp in zip(self.networks, inputs)]\n",
    "        x = torch.cat(network_inputs, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class CatNet(nn.Module):\n",
    "    def __init__(self, in_chs, out_ch, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.networks = []\n",
    "        for in_ch in in_chs:\n",
    "            self.networks.append(nn.Sequential(\n",
    "                nn.Conv2d(in_ch, 25, kernel_size, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(25, 50, kernel_size, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(50, 100, kernel_size, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2)\n",
    "            ))\n",
    "        \n",
    "        self.fc1 = nn.Linear(200 * 8 * 8, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 100)\n",
    "        self.fc3 = nn.Linear(100, out_ch)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        network_inputs = [net(inp) for net, inp in zip(self.networks, inputs)]\n",
    "        \n",
    "        x = torch.cat(network_inputs, 1)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MatMulNet(nn.Module):\n",
    "    def __init__(self, in_chs, out_ch, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.networks = []\n",
    "        for in_ch in in_chs:\n",
    "            self.networks.append(nn.Sequential(\n",
    "                nn.Conv2d(in_ch, 25, kernel_size, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(25, 50, kernel_size, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(50, 100, kernel_size, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2)\n",
    "            ))\n",
    "        \n",
    "        self.fc1 = nn.Linear(200 * 8 * 8, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 100)\n",
    "        self.fc3 = nn.Linear(100, out_ch)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        network_inputs = [net(inp) for net, inp in zip(self.networks, inputs)]\n",
    "        \n",
    "        x = torch.matmul(*network_inputs)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92c6c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_positions(positions):\n",
    "    return ['{0: .3f}'.format(x) for x in positions]\n",
    "\n",
    "def get_outputs(model, batch, inputs_idx):\n",
    "    inputs = batch[inputs_idx].to(device)\n",
    "    target = batch[-1].to(device)\n",
    "    outputs = model(inputs)\n",
    "    return outputs, target\n",
    "\n",
    "def print_loss(epoch, loss, outputs, target, is_train=True, is_debug=False):\n",
    "    loss_type = \"train loss:\" if is_train else \"valid loss:\"\n",
    "    print(\"epoch\", str(epoch), loss_type, str(loss))\n",
    "    if is_debug:\n",
    "        print(\"example pred:\", format_positions(outputs[0].tolist()))\n",
    "        print(\"example real:\", format_positions(target[0].tolist()))\n",
    "        \n",
    "\n",
    "def train_model(model, optimizer, input_fn, epochs, train_dataloader, valid_dataloader, target_idx=-1):\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            target = batch[target_idx].to(device)\n",
    "            outputs = model(input_fn(batch))\n",
    "            \n",
    "            loss = loss_func(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss = train_loss / (step + 1)\n",
    "        train_losses.append(train_loss)\n",
    "        print_loss(epoch, train_loss, outputs, target, is_train=True)\n",
    "        \n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        for step, batch in enumerate(valid_dataloader):\n",
    "            target = batch[target_idx].to(device)\n",
    "            outputs = model(input_fn(batch))\n",
    "            valid_loss += loss_func(outputs, target).item()\n",
    "        valid_loss = valid_loss / (step + 1)\n",
    "        valid_losses.append(valid_loss)\n",
    "        print_loss(epoch, valid_loss, outputs, target, is_train=False)\n",
    "    return train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1576d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_net = EarlyNet([4, 4], NUM_POSITIONS).to(device)\n",
    "\n",
    "rgb_net = BaseNet(4, NUM_POSITIONS).to(device)\n",
    "xyz_net = BaseNet(4, NUM_POSITIONS).to(device)\n",
    "late_net = LateNet([rgb_net, xyz_net], [NUM_POSITIONS, NUM_POSITIONS]).to(device)\n",
    "\n",
    "cat_net = CatNet([4, 4], NUM_POSITIONS).to(device)\n",
    "\n",
    "matmul_net = MatMulNet([4, 4], NUM_POSITIONS).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef2fbc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(model, learning_rate=0.001, epochs=10, train_dataloader=train_dataloader, valid_dataloader=valid_dataloader):\n",
    "    def get_inputs(batch):\n",
    "        inputs_rgb = batch[0].to(device)\n",
    "        inputs_xyz = batch[1].to(device)\n",
    "        return (inputs_rgb, inputs_xyz)\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    train_losses, valid_losses = train_model(\n",
    "        model,\n",
    "        optimizer,\n",
    "        get_inputs,\n",
    "        epochs,\n",
    "        train_dataloader,\n",
    "        valid_dataloader,\n",
    "    )\n",
    "    return train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "306c2059",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mexperiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mearly_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mexperiment\u001b[39m\u001b[34m(model, learning_rate, epochs, train_dataloader, valid_dataloader)\u001b[39m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (inputs_rgb, inputs_xyz)\n\u001b[32m      6\u001b[39m optimizer = Adam(model.parameters(), lr=learning_rate)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m train_losses, valid_losses = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m train_losses, valid_losses\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, optimizer, input_fn, epochs, train_dataloader, valid_dataloader, target_idx)\u001b[39m\n\u001b[32m     27\u001b[39m outputs = model(input_fn(batch))\n\u001b[32m     29\u001b[39m loss = loss_func(outputs, target)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m optimizer.step()\n\u001b[32m     32\u001b[39m train_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/acv-1rRgeGrz-py3.12/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/acv-1rRgeGrz-py3.12/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/acv-1rRgeGrz-py3.12/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "experiment(early_net, epochs=20, train_dataloader=train_dataloader, valid_dataloader=valid_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acv-1rRgeGrz-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
